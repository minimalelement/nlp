{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 6",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minimalelement/nlp/blob/main/Lab_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uMgAqVdMOxA",
        "outputId": "4ed41d28-4c35-4bf1-9439-6d668eac9275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connects ---> connect\n",
            "Connecting ---> connect\n",
            "Connections ---> connect\n",
            "Connected ---> connect\n",
            "Connection ---> connect\n",
            "Connectings ---> connect\n",
            "Connect ---> connect\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "words = ['Connects','Connecting','Connections','Connected','Connection','Connectings','Connect']\n",
        "for word in words:\n",
        "    print(word,\"--->\",porter.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = ['generous','generate','generously','generation']\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SefDKJ4nMhf4",
        "outputId": "21aceb81-90ad-49d0-a473-ed07732e117d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generous ---> generous\n",
            "generate ---> generat\n",
            "generously ---> generous\n",
            "generation ---> generat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "lancaster = LancasterStemmer()\n",
        "words = ['eating','eats','eaten','puts','putting']\n",
        "for word in words:\n",
        "    print(word,\"--->\",lancaster.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90j2lipMMlI9",
        "outputId": "7a404fe8-37ad-4abc-a91a-a3c36dd86030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating ---> eat\n",
            "eats ---> eat\n",
            "eaten ---> eat\n",
            "puts ---> put\n",
            "putting ---> put\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Porter Stemmer – PorterStemmer()"
      ],
      "metadata": {
        "id": "iIqnCqDD283f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WORD: CONNECT"
      ],
      "metadata": {
        "id": "bo1apt9X3gOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "words = ['Connects','Connecting','Connections','Connected','Connection','Connectings','Connect']\n",
        "for word in words:\n",
        "    print(word,\"--->\",porter.stem(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McmH7aHs2-Uu",
        "outputId": "e18b1d4c-bf0d-4243-9fd3-b15d055b6b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connects ---> connect\n",
            "Connecting ---> connect\n",
            "Connections ---> connect\n",
            "Connected ---> connect\n",
            "Connection ---> connect\n",
            "Connectings ---> connect\n",
            "Connect ---> connect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tz_Yih0O3cOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WORD:BUY"
      ],
      "metadata": {
        "id": "WfAD38Ui3lEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "words = ['Buys','BuyinG']\n",
        "for word in words:\n",
        "    print(word,\"--->\",porter.stem(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6aYN21y3MJK",
        "outputId": "8f754867-b3b6-4b6a-efa1-99ca836e6f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buys ---> buy\n",
            "BuyinG ---> buy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Snowball Stemmer – SnowballStemmer()\n",
        "faster and more logical than the original Porter Stemmer.\n"
      ],
      "metadata": {
        "id": "QGll9V7Y3vfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = ['generous','generate','generously','generation']\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiLeoKmg36Pm",
        "outputId": "fee2c5c4-be1d-4dba-b6da-7a78c8ad1a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generous ---> generous\n",
            "generate ---> generat\n",
            "generously ---> generous\n",
            "generation ---> generat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = ['killing','kills','killed','killation']\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "id": "UHP_Qsyl72e9",
        "outputId": "34f0cc3c-b6ba-4fe6-b364-00ae68d3bac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "killing ---> kill\n",
            "kills ---> kill\n",
            "killed ---> kill\n",
            "killation ---> killat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lancaster Stemmer – LancasterStemmer()\n",
        "Lancaster Stemmer is straightforward, although it often produces results with excessive stemming. Over-stemming renders stems non-linguistic or meaningless.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pxVZ8Xm13-UZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "lancaster = LancasterStemmer()\n",
        "words = ['eating','eats','eaten','puts','putting']\n",
        "for word in words:\n",
        "    print(word,\"--->\",lancaster.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzi8wG0s4F1X",
        "outputId": "4d3bc9cf-8d4b-4ddd-d796-f7cd3135ea49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating ---> eat\n",
            "eats ---> eat\n",
            "eaten ---> eat\n",
            "puts ---> put\n",
            "putting ---> put\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regexp Stemmer – RegexpStemmer()\n",
        "Regex stemmer identifies morphological affixes using regular expressions. Substrings matching the regular expressions will be discarded.\n"
      ],
      "metadata": {
        "id": "kly85dsx4JCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "words = ['mass','was','bee','computer','advisable']\n",
        "for word in words:\n",
        "  print(word,\"--->\",regexp.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8evQ3TY4ROH",
        "outputId": "592f9bb8-2e29-4ce7-a9ed-5fea3229e6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mass ---> mas\n",
            "was ---> was\n",
            "bee ---> bee\n",
            "computer ---> computer\n",
            "advisable ---> advis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparinghe stemers\n",
        "Porter vs Snowball vs Lancaster vs Regex\n"
      ],
      "metadata": {
        "id": "kXv631I34cAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer(language='english')\n",
        "regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}\".format(\"Word\",\"Porter Stemmer\",\"Snowball Stemmer\",\"Lancaster Stemmer\",'Regexp Stemmer'))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:30}{4:40}\".format(word,porter.stem(word),snowball.stem(word),lancaster.stem(word),regexp.stem(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1NrFMqm4ZVg",
        "outputId": "361a648a-f013-4b4d-fc1c-3346c4f808c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          \n",
            "friend              friend              friend              friend                        friend                                  \n",
            "friendship          friendship          friendship          friend                        friendship                              \n",
            "friends             friend              friend              friend                        friend                                  \n",
            "friendships         friendship          friendship          friend                        friendship                              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Text file for stemming"
      ],
      "metadata": {
        "id": "HG9Mplg6445k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputdata = open('/content/sample_data/sample.txt', 'r')\n",
        "data = inputdata.read()\n",
        "\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "AoHjKMXJ6EUo",
        "outputId": "320cbf30-1c6a-4618-a0d2-fad2b4eb5e98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we showed you how to conduct stemming in Python using the NLTK package for your natural language processing project. We looked at the several kinds of stemmers available in NLTK, as well as some examples of each. Then we conducted a comparative analysis of the outcomes provided by Porter vs Snowball vs Lancaster vs Regex variants, as well as the results produced by other methods. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "def stemming(data):\n",
        "    snowball = SnowballStemmer(language='english')\n",
        "    list=[]\n",
        "    for token in word_tokenize(data):\n",
        "        list.append(snowball.stem(token))\n",
        "    return ' '.join(list)"
      ],
      "metadata": {
        "id": "DSaZwQay6ZAT",
        "outputId": "f83a33e6-df66-437b-ecae-96cad2ff3457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Qe9gbP_n-uNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/sample_data/sample.txt',) as f:\n",
        "    text=f.read()\n",
        "print(stemming(text))"
      ],
      "metadata": {
        "id": "OKnzssFt6amT",
        "outputId": "90b72b11-5857-4aff-dbba-cd38afe488d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we show you how to conduct stem in python use the nltk packag for your natur languag process project . we look at the sever kind of stemmer avail in nltk , as well as some exampl of each . then we conduct a compar analysi of the outcom provid by porter vs snowbal vs lancast vs regex variant , as well as the result produc by other method .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using in different lanuages"
      ],
      "metadata": {
        "id": "1S6leT_7_m3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 - Import the German language Stemmer\n",
        " "
      ],
      "metadata": {
        "id": "68oeVJN28tNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import GermanStemmer"
      ],
      "metadata": {
        "id": "bUWq5Fb28sZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 - Store the german stemmer in a variable\n"
      ],
      "metadata": {
        "id": "9a32vlxr8ze5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "german_st = GermanStemmer()"
      ],
      "metadata": {
        "id": "RdmgPaUO8_vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 - Take sample words"
      ],
      "metadata": {
        "id": "t34qU7AL9EQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_sample = [\"Schreiben\",\"geschrieben\"]"
      ],
      "metadata": {
        "id": "ab14U6I79Auh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_sample1 = [\"Räuchern\",\"Räucher\"]"
      ],
      "metadata": {
        "id": "dXX5P3bn9i3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " step 4 :Apply stemming and print the results"
      ],
      "metadata": {
        "id": "fvVBrkAh9KKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stem_words = [german_st.stem(words) for words in token_sample1]\n",
        "print(\"Print the output after stemming:\",stem_words)"
      ],
      "metadata": {
        "id": "VpoIJL_Q9ORq",
        "outputId": "1210bfc7-00b7-4543-f0d1-1bfb8321a6fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Print the output after stemming: ['rauch', 'rauch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem_words = [german_st.stem(words) for words in token_sample]\n",
        "print(\"Print the output after stemming:\",stem_words)"
      ],
      "metadata": {
        "id": "dillXAG2_bYd",
        "outputId": "50dbae4f-b260-46f1-bf90-1cd0e5938684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Print the output after stemming: ['schreib', 'geschrieb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arabic Stemmming"
      ],
      "metadata": {
        "id": "PsEMIjtNB0sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.arlstem import ARLSTem"
      ],
      "metadata": {
        "id": "7E5DVvZHAmsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = ARLSTem()"
      ],
      "metadata": {
        "id": "jmnIfOnmAocY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('يعمل')"
      ],
      "metadata": {
        "id": "onXeiSUVArk8",
        "outputId": "80b7a202-4089-47ca-f272-ccaeabb23638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'عمل'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# French stemmer"
      ],
      "metadata": {
        "id": "miaCTgWEBP9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import FrenchStemmer"
      ],
      "metadata": {
        "id": "g2Wf-7mbBLCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = FrenchStemmer()"
      ],
      "metadata": {
        "id": "km2DnnDJBNHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('lessive')\n",
        "#washing"
      ],
      "metadata": {
        "id": "BkWPyXTfBV3o",
        "outputId": "d1a4c35a-7357-4a63-cbf8-6713a45b02a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lessiv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Russia Lanuanage"
      ],
      "metadata": {
        "id": "BKsWurnlCqnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer \n",
        "\n",
        "stemmer = SnowballStemmer(\"russian\") \n",
        "stemmer.stem(\"мытье\")"
      ],
      "metadata": {
        "id": "gqKY6UolCE1W",
        "outputId": "0b64e2e3-43a7-4599-ff60-a33f8bc531c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'мыт'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}